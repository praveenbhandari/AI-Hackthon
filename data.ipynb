{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185fd9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import time\n",
    "from ..utils.logger import SafetyLogger\n",
    "\n",
    "class SFDataService:\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://data.sfgov.org/resource/\"\n",
    "        self.datasets = {\n",
    "            'police_incidents': 'wg3w-h783.json',\n",
    "            'street_lights': '2gc3-4hv4.json',\n",
    "            '311_cases': 'vw6y-z8j6.json',\n",
    "        }\n",
    "        self.logger = SafetyLogger(\"SFDataService\")\n",
    "\n",
    "    async def fetch_dataset(\n",
    "        self,\n",
    "        dataset_name: str,\n",
    "        query_params: Dict,\n",
    "        timeout: int = 30\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Fetch data from SF OpenData API with logging\"\"\"\n",
    "        if dataset_name not in self.datasets:\n",
    "            self.logger.log_error(\n",
    "                \"InvalidDataset\",\n",
    "                f\"Unknown dataset: {dataset_name}\"\n",
    "            )\n",
    "            raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
    "\n",
    "        url = f\"{self.base_url}{self.datasets[dataset_name]}\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            self.logger.log_api_request(dataset_name, query_params)\n",
    "            \n",
    "            async with aiohttp.ClientSession() as session:\n",
    "                async with session.get(url, params=query_params, timeout=timeout) as response:\n",
    "                    response_time = (time.time() - start_time) * 1000  # Convert to ms\n",
    "                    \n",
    "                    self.logger.log_api_response(\n",
    "                        dataset_name,\n",
    "                        response.status,\n",
    "                        response_time\n",
    "                    )\n",
    "                    \n",
    "                    if response.status == 200:\n",
    "                        return await response.json()\n",
    "                    \n",
    "                    self.logger.log_error(\n",
    "                        \"APIError\",\n",
    "                        f\"API error for {dataset_name}\",\n",
    "                        {\"status_code\": response.status}\n",
    "                    )\n",
    "                    return []\n",
    "                    \n",
    "        except aiohttp.ClientError as e:\n",
    "            self.logger.log_error(\n",
    "                \"NetworkError\",\n",
    "                str(e),\n",
    "                {\"dataset\": dataset_name}\n",
    "            )\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            self.logger.log_error(\n",
    "                \"UnexpectedError\",\n",
    "                str(e),\n",
    "                {\"dataset\": dataset_name}\n",
    "            )\n",
    "            return []\n",
    "\n",
    "    async def get_area_safety_data(\n",
    "        self,\n",
    "        lat: float,\n",
    "        lng: float,\n",
    "        radius_meters: int = 500,\n",
    "        time_window_days: int = 30\n",
    "    ) -> Dict:\n",
    "        \"\"\"Get safety data for an area with logging\"\"\"\n",
    "        start_time = time.time()\n",
    "        location = {\"lat\": lat, \"lng\": lng}\n",
    "        \n",
    "        self.logger.log_api_request(\n",
    "            \"area_safety\",\n",
    "            {\n",
    "                \"location\": location,\n",
    "                \"radius_meters\": radius_meters,\n",
    "                \"time_window_days\": time_window_days\n",
    "            }\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            datasets = await asyncio.gather(\n",
    "                self.fetch_dataset('police_incidents', self._build_incident_query(lat, lng, radius_meters, time_window_days)),\n",
    "                self.fetch_dataset('street_lights', self._build_light_query(lat, lng, radius_meters)),\n",
    "                self.fetch_dataset('311_cases', self._build_cases_query(lat, lng, radius_meters, time_window_days))\n",
    "            )\n",
    "            \n",
    "            safety_data = self.analyze_safety_data(*datasets)\n",
    "            \n",
    "            response_time = (time.time() - start_time) * 1000\n",
    "            self.logger.log_api_response(\"area_safety\", 200, response_time)\n",
    "            \n",
    "            if safety_data.get('safety_score'):\n",
    "                self.logger.log_safety_calculation(\n",
    "                    location,\n",
    "                    safety_data['safety_score']\n",
    "                )\n",
    "            \n",
    "            return safety_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.log_error(\n",
    "                \"SafetyAnalysisError\",\n",
    "                str(e),\n",
    "                {\"location\": location}\n",
    "            )\n",
    "            raise\n",
    "\n",
    "    def _build_incident_query(self, lat: float, lng: float, radius: int, days: int) -> Dict:\n",
    "        \"\"\"Build query for incident data\"\"\"\n",
    "        time_threshold = datetime.now() - timedelta(days=days)\n",
    "        return {\n",
    "            '$where': f\"\"\"\n",
    "                within_circle(location, {lat}, {lng}, {radius})\n",
    "                AND date >= '{time_threshold.isoformat()}'\n",
    "            \"\"\",\n",
    "            '$select': 'category,date,time,location'\n",
    "        }\n",
    "\n",
    "    def _build_light_query(self, lat: float, lng: float, radius: int) -> Dict:\n",
    "        \"\"\"Build query for street light data\"\"\"\n",
    "        return {\n",
    "            '$where': f\"within_circle(location, {lat}, {lng}, {radius})\",\n",
    "            '$select': 'status,installation_date,maintenance_date'\n",
    "        }\n",
    "\n",
    "    def _build_cases_query(self, lat: float, lng: float, radius: int, days: int) -> Dict:\n",
    "        \"\"\"Build query for 311 cases data\"\"\"\n",
    "        time_threshold = datetime.now() - timedelta(days=days)\n",
    "        return {\n",
    "            '$where': f\"\"\"\n",
    "                within_circle(location, {lat}, {lng}, {radius})\n",
    "                AND created_date >= '{time_threshold.isoformat()}'\n",
    "            \"\"\",\n",
    "            '$select': 'category,status,created_date,closed_date'\n",
    "        }\n",
    "\n",
    "    def analyze_safety_data(self, incidents, lights, cases) -> Dict:\n",
    "        \"\"\"Analyze safety data with logging\"\"\"\n",
    "        try:\n",
    "            metrics = {}\n",
    "            \n",
    "            if incidents:\n",
    "                df_incidents = pd.DataFrame(incidents)\n",
    "                metrics['incident_analysis'] = self._analyze_incidents(df_incidents)\n",
    "                \n",
    "                self.logger.log_api_response(\n",
    "                    \"incident_analysis\",\n",
    "                    200,\n",
    "                    {\"total_incidents\": len(df_incidents)}\n",
    "                )\n",
    "            \n",
    "            if lights:\n",
    "                df_lights = pd.DataFrame(lights)\n",
    "                metrics['infrastructure'] = self._analyze_infrastructure(df_lights)\n",
    "                \n",
    "                self.logger.log_api_response(\n",
    "                    \"infrastructure_analysis\",\n",
    "                    200,\n",
    "                    {\"total_lights\": len(df_lights)}\n",
    "                )\n",
    "            \n",
    "            if cases:\n",
    "                df_cases = pd.DataFrame(cases)\n",
    "                metrics['response_metrics'] = self._analyze_response_times(df_cases)\n",
    "                \n",
    "                self.logger.log_api_response(\n",
    "                    \"response_analysis\",\n",
    "                    200,\n",
    "                    {\"total_cases\": len(df_cases)}\n",
    "                )\n",
    "            \n",
    "            metrics['safety_score'] = self._calculate_safety_score(metrics)\n",
    "            \n",
    "            return metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.log_error(\n",
    "                \"AnalysisError\",\n",
    "                str(e),\n",
    "                {\"data_sizes\": {\n",
    "                    \"incidents\": len(incidents),\n",
    "                    \"lights\": len(lights),\n",
    "                    \"cases\": len(cases)\n",
    "                }}\n",
    "            )\n",
    "            raise\n",
    "\n",
    "\n",
    "    def _analyze_incidents(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Analyze incident patterns and trends\"\"\"\n",
    "        try:\n",
    "            if df.empty:\n",
    "                return {}\n",
    "            \n",
    "            # Convert date column to datetime if not already\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            \n",
    "            # Hourly distribution\n",
    "            hourly_counts = df.groupby(df['date'].dt.hour).size()\n",
    "            \n",
    "            # Category analysis\n",
    "            category_counts = df['category'].value_counts()\n",
    "            \n",
    "            # Time-based patterns\n",
    "            time_patterns = {\n",
    "                'morning': len(df[df['date'].dt.hour.between(6, 11)]),\n",
    "                'afternoon': len(df[df['date'].dt.hour.between(12, 17)]),\n",
    "                'evening': len(df[df['date'].dt.hour.between(18, 23)]),\n",
    "                'night': len(df[df['date'].dt.hour.between(0, 5)])\n",
    "            }\n",
    "            \n",
    "            # Recent trend (last 7 days vs previous 7 days)\n",
    "            recent_mask = df['date'] >= (datetime.now() - timedelta(days=7))\n",
    "            previous_mask = ((df['date'] < (datetime.now() - timedelta(days=7))) & \n",
    "                        (df['date'] >= (datetime.now() - timedelta(days=14))))\n",
    "            \n",
    "            recent_count = len(df[recent_mask])\n",
    "            previous_count = len(df[previous_mask])\n",
    "            trend_change = ((recent_count - previous_count) / previous_count * 100) if previous_count > 0 else 0\n",
    "            \n",
    "            return {\n",
    "                'total_incidents': len(df),\n",
    "                'hourly_distribution': hourly_counts.to_dict(),\n",
    "                'category_distribution': category_counts.to_dict(),\n",
    "                'time_patterns': time_patterns,\n",
    "                'trend_change_percentage': trend_change,\n",
    "                'high_risk_hours': hourly_counts.nlargest(3).index.tolist(),\n",
    "                'most_common_categories': category_counts.nlargest(3).index.tolist()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.log_error(\n",
    "                \"IncidentAnalysisError\",\n",
    "                str(e),\n",
    "                {\"dataframe_info\": str(df.info())}\n",
    "            )\n",
    "            return {}\n",
    "\n",
    "    def _analyze_infrastructure(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Analyze infrastructure status and coverage\"\"\"\n",
    "        try:\n",
    "            if df.empty:\n",
    "                return {}\n",
    "            \n",
    "            # Basic counts\n",
    "            total_lights = len(df)\n",
    "            status_counts = df['status'].value_counts()\n",
    "            working_lights = status_counts.get('WORKING', 0)\n",
    "            \n",
    "            # Maintenance analysis\n",
    "            df['maintenance_date'] = pd.to_datetime(df['maintenance_date'])\n",
    "            recent_maintenance = len(df[\n",
    "                df['maintenance_date'] >= (datetime.now() - timedelta(days=90))\n",
    "            ])\n",
    "            \n",
    "            # Coverage calculation\n",
    "            coverage_score = (working_lights / total_lights * 100) if total_lights > 0 else 0\n",
    "            \n",
    "            return {\n",
    "                'total_lights': total_lights,\n",
    "                'working_lights': working_lights,\n",
    "                'status_distribution': status_counts.to_dict(),\n",
    "                'coverage_score': coverage_score,\n",
    "                'recent_maintenance_count': recent_maintenance,\n",
    "                'maintenance_percentage': (recent_maintenance / total_lights * 100) if total_lights > 0 else 0\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.log_error(\n",
    "                \"InfrastructureAnalysisError\",\n",
    "                str(e),\n",
    "                {\"dataframe_info\": str(df.info())}\n",
    "            )\n",
    "            return {}\n",
    "\n",
    "    def _analyze_response_times(self, df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Analyze emergency response patterns and efficiency\"\"\"\n",
    "        try:\n",
    "            if df.empty:\n",
    "                return {}\n",
    "            \n",
    "            # Convert date columns\n",
    "            df['created_date'] = pd.to_datetime(df['created_date'])\n",
    "            df['closed_date'] = pd.to_datetime(df['closed_date'])\n",
    "            \n",
    "            # Calculate response times in hours\n",
    "            df['response_time'] = (df['closed_date'] - df['created_date']).dt.total_seconds() / 3600\n",
    "            \n",
    "            # Calculate response time metrics\n",
    "            response_metrics = {\n",
    "                'mean_response_time': df['response_time'].mean(),\n",
    "                'median_response_time': df['response_time'].median(),\n",
    "                'percentiles': {\n",
    "                    '90th': df['response_time'].quantile(0.9),\n",
    "                    '95th': df['response_time'].quantile(0.95)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Category analysis\n",
    "            category_response_times = df.groupby('category')['response_time'].agg([\n",
    "                'mean',\n",
    "                'median',\n",
    "                'count'\n",
    "            ]).to_dict('index')\n",
    "            \n",
    "            # Time of day analysis\n",
    "            df['hour'] = df['created_date'].dt.hour\n",
    "            hourly_response_times = df.groupby('hour')['response_time'].mean().to_dict()\n",
    "            \n",
    "            return {\n",
    "                'response_metrics': response_metrics,\n",
    "                'category_performance': category_response_times,\n",
    "                'hourly_performance': hourly_response_times,\n",
    "                'total_cases': len(df),\n",
    "                'open_cases': len(df[df['closed_date'].isna()]),\n",
    "                'resolution_rate': (len(df[~df['closed_date'].isna()]) / len(df) * 100) if len(df) > 0 else 0\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.log_error(\n",
    "                \"ResponseAnalysisError\",\n",
    "                str(e),\n",
    "                {\"dataframe_info\": str(df.info())}\n",
    "            )\n",
    "            return {}\n",
    "\n",
    "    def _calculate_safety_score(self, metrics: Dict) -> float:\n",
    "        \"\"\"Calculate composite safety score based on all metrics\"\"\"\n",
    "        try:\n",
    "            score = 100.0\n",
    "            weights = {\n",
    "                'incidents': 0.4,\n",
    "                'infrastructure': 0.3,\n",
    "                'response': 0.3\n",
    "            }\n",
    "            \n",
    "            # Incident impact\n",
    "            if 'incident_analysis' in metrics:\n",
    "                incident_data = metrics['incident_analysis']\n",
    "                total_incidents = incident_data.get('total_incidents', 0)\n",
    "                trend_change = incident_data.get('trend_change_percentage', 0)\n",
    "                \n",
    "                # Reduce score based on incident count and trend\n",
    "                incident_impact = min(50, total_incidents * 2)  # Cap at 50 point reduction\n",
    "                trend_impact = max(-10, min(10, trend_change / 10))  # +/- 10 points max\n",
    "                \n",
    "                score -= incident_impact * weights['incidents']\n",
    "                score += trend_impact * weights['incidents']\n",
    "            \n",
    "            # Infrastructure impact\n",
    "            if 'infrastructure' in metrics:\n",
    "                infra_data = metrics['infrastructure']\n",
    "                coverage_score = infra_data.get('coverage_score', 0)\n",
    "                \n",
    "                # Reduce score based on infrastructure coverage\n",
    "                score += (coverage_score - 100) * weights['infrastructure']\n",
    "            \n",
    "            # Response time impact\n",
    "            if 'response_metrics' in metrics:\n",
    "                response_data = metrics['response_metrics']\n",
    "                resolution_rate = response_data.get('resolution_rate', 0)\n",
    "                \n",
    "                # Reduce score based on response performance\n",
    "                score += (resolution_rate - 100) * weights['response']\n",
    "            \n",
    "            return max(0, min(100, score))\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.log_error(\n",
    "                \"ScoreCalculationError\",\n",
    "                str(e),\n",
    "                {\"metrics\": metrics}\n",
    "            )\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9790ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e37b0a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w_/6x800hl95xv8j0zzn6nhwgnw0000gn/T/ipykernel_28534/4271365712.py:1: DtypeWarning: Columns (18,21,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data =pd.read_csv('Police_Department_Incident_Reports__2018_to_Present_20250621.csv')\n"
     ]
    }
   ],
   "source": [
    "data =pd.read_csv('Police_Department_Incident_Reports__2018_to_Present_20250621.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35114ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Incident Datetime</th>\n",
       "      <th>Incident Date</th>\n",
       "      <th>Incident Time</th>\n",
       "      <th>Incident Year</th>\n",
       "      <th>Incident Day of Week</th>\n",
       "      <th>Report Datetime</th>\n",
       "      <th>Incident ID</th>\n",
       "      <th>Incident Number</th>\n",
       "      <th>CAD Number</th>\n",
       "      <th>...</th>\n",
       "      <th>data_as_of</th>\n",
       "      <th>data_loaded_at</th>\n",
       "      <th>Neighborhoods</th>\n",
       "      <th>ESNCAG - Boundary File</th>\n",
       "      <th>Central Market/Tenderloin Boundary Polygon - Updated</th>\n",
       "      <th>Civic Center Harm Reduction Project Boundary</th>\n",
       "      <th>HSOC Zones as of 2018-06-05</th>\n",
       "      <th>Invest In Neighborhoods (IIN) Areas</th>\n",
       "      <th>Current Supervisor Districts</th>\n",
       "      <th>Current Police Districts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139275426030</td>\n",
       "      <td>2024/05/23 08:58:00 AM</td>\n",
       "      <td>2024/05/23</td>\n",
       "      <td>08:58</td>\n",
       "      <td>2024</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2024/05/23 09:08:00 AM</td>\n",
       "      <td>1392754</td>\n",
       "      <td>240322949</td>\n",
       "      <td>241440743.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2025/06/12 10:07:02 AM</td>\n",
       "      <td>2025/06/13 09:52:57 AM</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76059904134</td>\n",
       "      <td>2019/01/18 09:25:00 AM</td>\n",
       "      <td>2019/01/18</td>\n",
       "      <td>09:25</td>\n",
       "      <td>2019</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2019/01/18 10:42:00 AM</td>\n",
       "      <td>760599</td>\n",
       "      <td>190043203</td>\n",
       "      <td>190181332.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2025/06/12 10:07:02 AM</td>\n",
       "      <td>2025/06/13 09:52:57 AM</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77207504134</td>\n",
       "      <td>2019/02/20 11:40:00 AM</td>\n",
       "      <td>2019/02/20</td>\n",
       "      <td>11:40</td>\n",
       "      <td>2019</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2019/02/20 01:51:00 PM</td>\n",
       "      <td>772075</td>\n",
       "      <td>190127653</td>\n",
       "      <td>190512164.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2025/06/12 10:07:02 AM</td>\n",
       "      <td>2025/06/13 09:52:57 AM</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83296309027</td>\n",
       "      <td>2019/08/10 05:05:00 PM</td>\n",
       "      <td>2019/08/10</td>\n",
       "      <td>17:05</td>\n",
       "      <td>2019</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2019/08/10 05:08:00 PM</td>\n",
       "      <td>832963</td>\n",
       "      <td>190586764</td>\n",
       "      <td>192223042.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2025/06/12 10:07:02 AM</td>\n",
       "      <td>2025/06/13 09:52:57 AM</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85420604134</td>\n",
       "      <td>2019/10/03 09:33:00 PM</td>\n",
       "      <td>2019/10/03</td>\n",
       "      <td>21:33</td>\n",
       "      <td>2019</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2019/10/03 09:33:00 PM</td>\n",
       "      <td>854206</td>\n",
       "      <td>190744348</td>\n",
       "      <td>192764124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2025/06/12 10:07:02 AM</td>\n",
       "      <td>2025/06/13 09:52:57 AM</td>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Row ID       Incident Datetime Incident Date Incident Time  \\\n",
       "0  139275426030  2024/05/23 08:58:00 AM    2024/05/23         08:58   \n",
       "1   76059904134  2019/01/18 09:25:00 AM    2019/01/18         09:25   \n",
       "2   77207504134  2019/02/20 11:40:00 AM    2019/02/20         11:40   \n",
       "3   83296309027  2019/08/10 05:05:00 PM    2019/08/10         17:05   \n",
       "4   85420604134  2019/10/03 09:33:00 PM    2019/10/03         21:33   \n",
       "\n",
       "   Incident Year Incident Day of Week         Report Datetime  Incident ID  \\\n",
       "0           2024             Thursday  2024/05/23 09:08:00 AM      1392754   \n",
       "1           2019               Friday  2019/01/18 10:42:00 AM       760599   \n",
       "2           2019            Wednesday  2019/02/20 01:51:00 PM       772075   \n",
       "3           2019             Saturday  2019/08/10 05:08:00 PM       832963   \n",
       "4           2019             Thursday  2019/10/03 09:33:00 PM       854206   \n",
       "\n",
       "   Incident Number   CAD Number  ...              data_as_of  \\\n",
       "0        240322949  241440743.0  ...  2025/06/12 10:07:02 AM   \n",
       "1        190043203  190181332.0  ...  2025/06/12 10:07:02 AM   \n",
       "2        190127653  190512164.0  ...  2025/06/12 10:07:02 AM   \n",
       "3        190586764  192223042.0  ...  2025/06/12 10:07:02 AM   \n",
       "4        190744348  192764124.0  ...  2025/06/12 10:07:02 AM   \n",
       "\n",
       "           data_loaded_at Neighborhoods  ESNCAG - Boundary File  \\\n",
       "0  2025/06/13 09:52:57 AM          54.0                     NaN   \n",
       "1  2025/06/13 09:52:57 AM          32.0                     NaN   \n",
       "2  2025/06/13 09:52:57 AM          53.0                     NaN   \n",
       "3  2025/06/13 09:52:57 AM          53.0                     NaN   \n",
       "4  2025/06/13 09:52:57 AM         109.0                     NaN   \n",
       "\n",
       "  Central Market/Tenderloin Boundary Polygon - Updated  \\\n",
       "0                                                NaN     \n",
       "1                                                NaN     \n",
       "2                                                NaN     \n",
       "3                                                NaN     \n",
       "4                                                NaN     \n",
       "\n",
       "  Civic Center Harm Reduction Project Boundary HSOC Zones as of 2018-06-05  \\\n",
       "0                                          NaN                         2.0   \n",
       "1                                          NaN                         NaN   \n",
       "2                                          NaN                         3.0   \n",
       "3                                          NaN                         3.0   \n",
       "4                                          NaN                         NaN   \n",
       "\n",
       "  Invest In Neighborhoods (IIN) Areas Current Supervisor Districts  \\\n",
       "0                                 NaN                          9.0   \n",
       "1                                 NaN                         10.0   \n",
       "2                                 NaN                          2.0   \n",
       "3                                 NaN                          2.0   \n",
       "4                                 NaN                         11.0   \n",
       "\n",
       "   Current Police Districts  \n",
       "0                       3.0  \n",
       "1                       1.0  \n",
       "2                       3.0  \n",
       "3                       3.0  \n",
       "4                       7.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb87e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
